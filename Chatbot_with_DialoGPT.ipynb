{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT1kYePAg_6U",
        "outputId": "80050ace-2393-4bc1-8acd-927f2b5bea42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Hi! I'm here to chat with you. Type 'exit' to stop the conversation.\n",
            "You: Hello, How are you?\n",
            "Chatbot: I'm good, how are you?\n",
            "You: Yes, I am also fine.\n",
            "Chatbot: I'm glad to hear that.\n",
            "You: What is Python?\n",
            "Chatbot: It's a language.\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def chat(input_text, chat_history_ids=None):\n",
        "    new_input_ids = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    bot_input_ids = new_input_ids if chat_history_ids is None else torch.cat([chat_history_ids, new_input_ids], dim=-1)\n",
        "\n",
        "    response_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    response = tokenizer.decode(response_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "    return response, response_ids\n",
        "\n",
        "chat_history_ids = None\n",
        "\n",
        "print(\"Chatbot: Hi! I'm here to chat with you. Type 'exit' to stop the conversation.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Chatbot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    response, chat_history_ids = chat(user_input, chat_history_ids)\n",
        "\n",
        "    print(\"You:\", user_input) \n",
        "    print(\"Chatbot:\", response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
